{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b545a8ba4cc54da988e1fbfa16191752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_085bfe229bea4f6a979a12a949accb6e",
              "IPY_MODEL_99034197bfb24c238910c464cf0127c4",
              "IPY_MODEL_b7fbd82533d44bfe991d2c4e64bb69f3"
            ],
            "layout": "IPY_MODEL_cfa010d9b6704937ba631b706c47edb6"
          }
        },
        "085bfe229bea4f6a979a12a949accb6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4334ee6a1ea847e6a80166893f098f5c",
            "placeholder": "​",
            "style": "IPY_MODEL_0c2ca7f93dd549e6b707722f29732a5e",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "99034197bfb24c238910c464cf0127c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9e3af7cf534ae5b49c8ac34fa241b3",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3551fe4de1cb4f41942d09f4d0bb2346",
            "value": 6
          }
        },
        "b7fbd82533d44bfe991d2c4e64bb69f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7f7bc9aa46748d2a0908df04d8f9474",
            "placeholder": "​",
            "style": "IPY_MODEL_b75d3be7f8fe417fbaadb4f416c92266",
            "value": " 6/6 [00:01&lt;00:00,  6.97it/s]"
          }
        },
        "cfa010d9b6704937ba631b706c47edb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4334ee6a1ea847e6a80166893f098f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2ca7f93dd549e6b707722f29732a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b9e3af7cf534ae5b49c8ac34fa241b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3551fe4de1cb4f41942d09f4d0bb2346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7f7bc9aa46748d2a0908df04d8f9474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b75d3be7f8fe417fbaadb4f416c92266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c2a8cf3a2cf48fabe20e42ff5107c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eb1346e6fcc4cae9747e0c51fc46406",
              "IPY_MODEL_1a97f865692a40a296b894d4a07bc5db",
              "IPY_MODEL_442a6bba57b74c6aa81deb97cde33c5e"
            ],
            "layout": "IPY_MODEL_1bd4505b92244c6f9ccfaf96f8a0a1fb"
          }
        },
        "0eb1346e6fcc4cae9747e0c51fc46406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_713a5f179c024d969df341a47ce12be3",
            "placeholder": "​",
            "style": "IPY_MODEL_fc76578e5f0140e6b774aa4bdfb9e33b",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "1a97f865692a40a296b894d4a07bc5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d6589c42ad4dab84a279b6bd9502dc",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73293271801849c7a0d5bc7c725bc216",
            "value": 6
          }
        },
        "442a6bba57b74c6aa81deb97cde33c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73dd5f66f455462ea007c748eac3903b",
            "placeholder": "​",
            "style": "IPY_MODEL_8b2ea9d0c7504834ad73835d9d7d8b73",
            "value": " 6/6 [00:01&lt;00:00,  7.07it/s]"
          }
        },
        "1bd4505b92244c6f9ccfaf96f8a0a1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713a5f179c024d969df341a47ce12be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc76578e5f0140e6b774aa4bdfb9e33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9d6589c42ad4dab84a279b6bd9502dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73293271801849c7a0d5bc7c725bc216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73dd5f66f455462ea007c748eac3903b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2ea9d0c7504834ad73835d9d7d8b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "664ec976b2c9418a8079272a1a3e1aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d217d5f87e44496ebdf59d6fbabdd010",
              "IPY_MODEL_b5306c158e5c44879a15c0225293efa1",
              "IPY_MODEL_c1fb30bb4c67497ab53d41a4c5cfaa13"
            ],
            "layout": "IPY_MODEL_85094a9858114417a7822748c84847df"
          }
        },
        "d217d5f87e44496ebdf59d6fbabdd010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a2effbdb9594f97af69f6613125eb3d",
            "placeholder": "​",
            "style": "IPY_MODEL_9d438cb1340e48d9bb2c4f42c72c933f",
            "value": "100%"
          }
        },
        "b5306c158e5c44879a15c0225293efa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e99278469f9646bf96bd3aba89be30e3",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc7a82d898ec4e48a8e7ca839149d69e",
            "value": 4
          }
        },
        "c1fb30bb4c67497ab53d41a4c5cfaa13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4524ef17c7ce42f89e05046621d44c0b",
            "placeholder": "​",
            "style": "IPY_MODEL_3d35fe921daf4b91b6b7b3fb098b9bdf",
            "value": " 4/4 [00:00&lt;00:00,  5.54it/s]"
          }
        },
        "85094a9858114417a7822748c84847df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2effbdb9594f97af69f6613125eb3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d438cb1340e48d9bb2c4f42c72c933f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e99278469f9646bf96bd3aba89be30e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7a82d898ec4e48a8e7ca839149d69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4524ef17c7ce42f89e05046621d44c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d35fe921daf4b91b6b7b3fb098b9bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#AnimateDiffPipeline"
      ],
      "metadata": {
        "id": "4yl7IryNZ1Iw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgIIllJC_w04"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers accelerate diffusers imageio-ffmpeg\n",
        "import torch\n",
        "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
        "from diffusers.utils import export_to_gif\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "device = \"cuda\"\n",
        "dtype = torch.float16\n",
        "\n",
        "step = 4  # Options: [1,2,4,8]\n",
        "repo = \"ByteDance/AnimateDiff-Lightning\"\n",
        "ckpt = f\"animatediff_lightning_{step}step_diffusers.safetensors\"\n",
        "base = \"emilianJR/epiCRealism\"  # Choose to base model.\n",
        "\n",
        "adapter = MotionAdapter().to(device, dtype)\n",
        "adapter.load_state_dict(load_file(hf_hub_download(repo ,ckpt), device=device))\n",
        "pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
        "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
        "\n",
        "output = pipe(prompt=\"crack two eggs into a bowl\", guidance_scale=1.0, num_inference_steps=step)\n",
        "export_to_gif(output.frames[0], \"animation.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tuning\n"
      ],
      "metadata": {
        "id": "Z-TX9bhXe6t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLY16IFv1CZx",
        "outputId": "392aa4cd-8cec-44d9-808b-28373d29b8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from diffusers import AnimateDiffPipeline, MotionAdapter\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "# Set up the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dtype = torch.float16"
      ],
      "metadata": {
        "id": "Lh5NumLbup-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Data path\n",
        "frame_dir = \"/content/drive/Shareddrives/DATA 298B Team 8/298A/processed_data/train\"\n",
        "annotation_path = \"/content/drive/Shareddrives/DATA 298B Team 8/298A/youcook/annotations/youcookii_annotations_trainval.json\"\n",
        "os.makedirs(frame_dir, exist_ok=True)\n",
        "\n",
        "class YouCook2Dataset(Dataset):\n",
        "    def __init__(self, annotation_path, frame_path, transform=None):\n",
        "        with open(annotation_path, \"r\") as f:\n",
        "            self.annotations = json.load(f)\n",
        "        self.frame_path = frame_path\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        # Get all video IDs in `frame_dir`\n",
        "        self.existing_video_ids = set([f.split(\"_sentence\")[0] for f in os.listdir(self.frame_path) if \"_frames\" in f])\n",
        "\n",
        "        # Load data\n",
        "        self.data = self.prepare_data()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\" Parse JSON to get video frames and corresponding captions \"\"\"\n",
        "        data = []\n",
        "\n",
        "        for video_id, info in self.annotations['database'].items():\n",
        "            if video_id not in self.existing_video_ids:\n",
        "                continue\n",
        "\n",
        "            for annotation_idx, annotation in enumerate(info['annotations']):\n",
        "                sentence = annotation[\"sentence\"]\n",
        "                sentence_folder = f\"{video_id}_sentence{annotation_idx}_frames\"\n",
        "                video_path = os.path.join(self.frame_path, sentence_folder)\n",
        "\n",
        "                if not os.path.exists(video_path):\n",
        "                    continue\n",
        "\n",
        "                # Get `frame_*.jpg` files\n",
        "                frames = sorted(glob.glob(os.path.join(video_path, \"frame_*.jpg\")))\n",
        "                if not frames:\n",
        "                    continue\n",
        "\n",
        "                data.append((frames[:8], sentence))  # Select the first 8 frames\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_paths, sentence = self.data[idx]\n",
        "        frames = torch.stack([self.transform(Image.open(fp).convert(\"RGB\")) for fp in frame_paths])\n",
        "        return frames, sentence\n",
        "\n",
        "dataset = YouCook2Dataset(annotation_path, frame_dir)\n",
        "print(\"Dataset loaded successfully, total samples:\", len(dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJMwjfk9oRTk",
        "outputId": "44213645-84f1-4301-fed5-9a8f77fbc087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully, total samples: 8634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade transformers accelerate diffusers imageio-ffmpeg\n",
        "import torch\n",
        "import gc\n",
        "import numpy as np\n",
        "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
        "from diffusers.utils import export_to_gif\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "device = \"cuda\"\n",
        "dtype = torch.float16\n",
        "\n",
        "step = 4  # Options: [1,2,4,8]\n",
        "repo = \"ByteDance/AnimateDiff-Lightning\"\n",
        "ckpt = f\"animatediff_lightning_{step}step_diffusers.safetensors\"\n",
        "base = \"emilianJR/epiCRealism\"  # Choose the base model.\n",
        "\n",
        "adapter = MotionAdapter().to(device, dtype)\n",
        "adapter.load_state_dict(load_file(hf_hub_download(repo, ckpt), device=device))\n",
        "pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
        "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
        "\n",
        "\n",
        "# Load pre-trained MotionAdapter\n",
        "repo = \"ByteDance/AnimateDiff-Lightning\"\n",
        "ckpt = f\"animatediff_lightning_{step}step_diffusers.safetensors\"\n",
        "\n",
        "adapter = MotionAdapter().to(device, dtype)\n",
        "adapter.load_state_dict(load_file(hf_hub_download(repo, ckpt), device=device))  # Load the official MotionAdapter pre-trained model\n",
        "adapter.train()  # Set to training mode\n",
        "\n",
        "# Enable training for the entire MotionAdapter\n",
        "for param in adapter.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 3\n",
        "learning_rate = 3e-5\n",
        "# max_batches = 4  # Train more batches\n",
        "\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "optimizer = AdamW(adapter.parameters(), lr=learning_rate)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs // 2, eta_min=1e-6)  # Smooth learning rate decay\n",
        "\n",
        "# Attach the fine-tuned MotionAdapter\n",
        "pipe.motion_adapter = adapter\n",
        "\n",
        "# Train MotionAdapter (without LoRA)\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
        "        # if batch_idx >= max_batches:\n",
        "        #     break  # Train only the first 50 batches\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Load input data\n",
        "        frames, captions = batch\n",
        "        frames = frames.to(device, dtype)  # [batch, frames, channels, height, width]\n",
        "\n",
        "        # Process text input\n",
        "        if isinstance(captions, tuple):\n",
        "            prompts = [str(c) for c in captions]\n",
        "        elif isinstance(captions, list):\n",
        "            prompts = [str(c) for c in captions]\n",
        "        else:\n",
        "            prompts = [str(captions)]\n",
        "        prompt = \" \".join(prompts)\n",
        "\n",
        "        # Generate animation\n",
        "        output = pipe(prompt=prompt, guidance_scale=1.0, num_inference_steps=step)\n",
        "\n",
        "        # Ensure output.frames is a NumPy array\n",
        "        frames_np = np.array(output.frames)\n",
        "        print(f\"Shape of output.frames: {frames_np.shape}\")  # Debugging\n",
        "\n",
        "        # Ensure output.frames shape is (frames, H, W, C)\n",
        "        if frames_np.ndim == 5:  # Possibly (batch, frames, H, W, C)\n",
        "            frames_np = frames_np.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "        # Convert to PyTorch Tensor, ensure requires_grad=True\n",
        "        generated_frames = torch.as_tensor(frames_np, device=device, dtype=dtype).clone().detach().requires_grad_() / 255.0\n",
        "\n",
        "        # Adjust channel order (frames, H, W, C) -> (frames, C, H, W)\n",
        "        generated_frames = generated_frames.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Add batch dimension (batch, frames, C, H, W)\n",
        "        generated_frames = generated_frames.unsqueeze(0)\n",
        "\n",
        "        # Interpolate only supports (N, C, H, W), so flatten frames dimension first\n",
        "        b, f, c, h, w = generated_frames.shape\n",
        "        generated_frames = generated_frames.view(b * f, c, h, w)\n",
        "\n",
        "        # Resize to 256x256\n",
        "        generated_frames = torch.nn.functional.interpolate(\n",
        "            generated_frames, size=(256, 256), mode='bilinear', align_corners=False\n",
        "        )\n",
        "\n",
        "        # Restore frames dimension (batch, frames, C, H, W)\n",
        "        generated_frames = generated_frames.view(b, f, c, 256, 256)\n",
        "\n",
        "        # Ensure consistent number of frames\n",
        "        min_frames = min(generated_frames.shape[1], frames.shape[1])\n",
        "        generated_frames = generated_frames[:, :min_frames, :, :, :]\n",
        "        frames = frames[:, :min_frames, :, :, :]\n",
        "\n",
        "        # Ensure frames also require gradients\n",
        "        frames = frames.clone().detach().requires_grad_()\n",
        "\n",
        "        # Compute loss\n",
        "        # loss = F.mse_loss(generated_frames, frames)\n",
        "        loss = F.smooth_l1_loss(generated_frames, frames, beta=0.5)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Save the fully fine-tuned MotionAdapter\n",
        "torch.save(adapter.state_dict(), \"/content/drive/Shareddrives/DATA 298B Team 8/CODE/motion_adapter_finetuned_4.6.pth\")\n",
        "print(\"Training complete, saved motion_adapter_finetuned.pth\")\n",
        "\n",
        "# Reload the fully fine-tuned MotionAdapter\n",
        "adapter = MotionAdapter().to(device, dtype)\n",
        "\n",
        "# Directly load the full fine-tuned MotionAdapter weights\n",
        "state_dict = torch.load(\"/content/drive/Shareddrives/DATA 298B Team 8/CODE/motion_adapter_finetuned_4.6.pth\", map_location=device)  # No need for `weights_only=True`\n",
        "adapter.load_state_dict(state_dict, strict=True)  # `strict=True` ensures weights match exactly\n",
        "\n",
        "pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
        "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
        "\n",
        "output = pipe(prompt=\"crack two eggs into a bowl\", guidance_scale=1.0, num_inference_steps=step)\n",
        "export_to_gif(output.frames[0], \"/content/drive/Shareddrives/DATA 298B Team 8/CODE/AnimateDiff_finetuned_animation_4.6.gif\")\n"
      ],
      "metadata": {
        "id": "LtuBkGPGVycd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio diffusers huggingface_hub safetensors torch torchvision\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "import numpy as np\n",
        "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "from PIL import Image\n",
        "\n",
        "# Define Gradio processing function\n",
        "def generate_animation(prompt):\n",
        "    \"\"\"Generate an animation based on the user input text.\"\"\"\n",
        "    output = pipe(prompt=prompt, guidance_scale=1.0, num_inference_steps=step)\n",
        "\n",
        "    # Ensure output is in NumPy format\n",
        "    frames_np = np.array(output.frames, dtype=np.float32)  # Ensure float32 for precision\n",
        "\n",
        "    # Handle dimensions\n",
        "    if frames_np.ndim == 5:  # Possibly (batch, frames, H, W, C)\n",
        "        frames_np = frames_np.squeeze(0)\n",
        "\n",
        "    # Normalize values to range [0, 1] if they are outside the range\n",
        "    if frames_np.min() < 0 or frames_np.max() > 1:\n",
        "        frames_np = (frames_np - frames_np.min()) / (frames_np.max() - frames_np.min())\n",
        "\n",
        "    # Convert to RGB format (if necessary, some models output BGR or grayscale)\n",
        "    if frames_np.shape[-1] == 3:  # Assuming (frames, H, W, C)\n",
        "        frames_np = frames_np[..., ::-1]  # Convert BGR to RGB if necessary\n",
        "\n",
        "    # Convert NumPy array to PIL format\n",
        "    frames_pil = [Image.fromarray((frame * 255).astype(np.uint8), mode=\"RGB\") for frame in frames_np]\n",
        "\n",
        "    # Generate GIF\n",
        "    gif_path = \"/content/generated_animation.gif\"\n",
        "    frames_pil[0].save(gif_path, save_all=True, append_images=frames_pil[1:], duration=100, loop=0)\n",
        "\n",
        "    return gif_path\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_animation,\n",
        "    inputs=gr.Textbox(label=\"Enter a text prompt\"),\n",
        "    outputs=gr.Image(type=\"filepath\", label=\"Generated Animation\"),\n",
        "    title=\"Text to Video Web App\",\n",
        "    description=\"Enter a text description and generate an animation.\"\n",
        ")\n",
        "\n",
        "# Launch Web App\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-bHjzFx-4P6o",
        "outputId": "9b46280a-89f8-4e60-fa9f-ac2e582cf669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.20.0)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://08008f3358ae9b0d96.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://08008f3358ae9b0d96.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lpips"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXd5FxNkV9ue",
        "outputId": "997207d1-3f7e-4f4e-c6c7-7ab31c8c9042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from lpips) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.2.1->lpips) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lpips\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lpips-0.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute all evaluation metrics for each comparison"
      ],
      "metadata": {
        "id": "FiGcDHrV_S_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import lpips\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from scipy.linalg import sqrtm\n",
        "\n",
        "# Ensure GPU usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load GIF files from user-provided paths\n",
        "file_paths = {\n",
        "    \"original\": \"Animate1.gif\",  # Pre-trained model result\n",
        "    \"2epochs\": \"Animate2.gif\",  # Another comparison GIF\n",
        "    \"10epochs\": \"Animate3.gif\",  # Fine-tuned model result\n",
        "}\n",
        "\n",
        "# Load GIF and convert to tensor\n",
        "def load_gif_frames(file_path, max_frames=3, resize=(64, 64)):\n",
        "    gif = imageio.mimread(file_path)\n",
        "    num_frames = min(len(gif), max_frames)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(resize),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    frames = torch.stack([transform(transforms.ToPILImage()(gif[i])) for i in np.linspace(0, len(gif)-1, num_frames, dtype=int)])\n",
        "    return frames.to(device)\n",
        "\n",
        "# Load all GIFs\n",
        "gif_frames = {key: load_gif_frames(path) for key, path in file_paths.items()}\n",
        "\n",
        "# Compute SSIM\n",
        "def compute_avg_ssim(frames1, frames2):\n",
        "    min_frames = min(frames1.shape[0], frames2.shape[0])\n",
        "    frames1, frames2 = frames1[:min_frames].cpu().numpy(), frames2[:min_frames].cpu().numpy()\n",
        "\n",
        "    ssim_values = [\n",
        "        ssim(frames1[i].mean(axis=0), frames2[i].mean(axis=0), data_range=1.0)\n",
        "        for i in range(min_frames)\n",
        "    ]\n",
        "    return np.mean(ssim_values)\n",
        "\n",
        "# Compute PSNR\n",
        "def compute_avg_psnr(frames1, frames2):\n",
        "    min_frames = min(frames1.shape[0], frames2.shape[0])\n",
        "    frames1, frames2 = frames1[:min_frames].cpu().numpy(), frames2[:min_frames].cpu().numpy()\n",
        "\n",
        "    psnr_values = [\n",
        "        psnr(frames1[i], frames2[i], data_range=1.0)\n",
        "        for i in range(min_frames)\n",
        "    ]\n",
        "    return np.mean(psnr_values)\n",
        "\n",
        "# Compute LPIPS (Perceptual Loss)\n",
        "loss_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "def compute_avg_lpips(frames1, frames2):\n",
        "    min_frames = min(frames1.shape[0], frames2.shape[0])\n",
        "    lpips_values = [\n",
        "        loss_fn(frames1[i].unsqueeze(0), frames2[i].unsqueeze(0)).item()\n",
        "        for i in range(min_frames)\n",
        "    ]\n",
        "    return np.mean(lpips_values)\n",
        "\n",
        "# Compute FVD (Optimized Version)\n",
        "def compute_fvd(frames1, frames2):\n",
        "    frames1, frames2 = frames1.view(frames1.shape[0], -1).cpu().numpy(), frames2.view(frames2.shape[0], -1).cpu().numpy()\n",
        "\n",
        "    mu1, sigma1 = np.mean(frames1, axis=0), np.cov(frames1, rowvar=False)\n",
        "    mu2, sigma2 = np.mean(frames2, axis=0), np.cov(frames2, rowvar=False)\n",
        "\n",
        "    tr_sigma = np.trace(sigma1) + np.trace(sigma2) - 2 * np.sqrt(np.trace(sigma1) * np.trace(sigma2))\n",
        "    return np.sum((mu1 - mu2) ** 2) + tr_sigma\n",
        "\n",
        "# Compute Optical Flow (Motion Consistency)\n",
        "def compute_optical_flow(frames):\n",
        "    flows = []\n",
        "    for i in range(len(frames) - 1):\n",
        "        prev, nxt = frames[i].cpu().numpy().transpose(1, 2, 0), frames[i + 1].cpu().numpy().transpose(1, 2, 0)\n",
        "        prev_gray, nxt_gray = cv2.cvtColor(prev, cv2.COLOR_RGB2GRAY), cv2.cvtColor(nxt, cv2.COLOR_RGB2GRAY)\n",
        "        flow = cv2.calcOpticalFlowFarneback(prev_gray, nxt_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "        flows.append(np.mean(np.abs(flow)))\n",
        "    return np.mean(flows)\n",
        "\n",
        "# Compute all evaluation metrics for each comparison\n",
        "comparisons = {\n",
        "    \"2epochs vs Original\": (\"original\", \"2epochs\"),\n",
        "    \"10epochs vs Original\": (\"original\", \"10epochs\"),\n",
        "    \"10epochs vs 2epochs\": (\"2epochs\", \"10epochs\"),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, (gif1, gif2) in comparisons.items():\n",
        "    results[name] = {\n",
        "        \"SSIM\": compute_avg_ssim(gif_frames[gif1], gif_frames[gif2]),\n",
        "        \"PSNR\": compute_avg_psnr(gif_frames[gif1], gif_frames[gif2]),\n",
        "        \"LPIPS\": compute_avg_lpips(gif_frames[gif1], gif_frames[gif2]),\n",
        "        \"FVD\": compute_fvd(gif_frames[gif1], gif_frames[gif2]),\n",
        "        \"Optical Flow\": compute_optical_flow(gif_frames[gif2]),\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "df_results = pd.DataFrame(results).T\n",
        "from IPython.display import display\n",
        "display(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_nLXLiL3a8uz",
        "outputId": "2baa8a63-4d5b-472c-8a0b-697174aa029a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                          SSIM       PSNR     LPIPS          FVD  Optical Flow\n",
              "2epochs vs Original   0.011030  10.244824  0.121561  1068.556276  5.618801e-06\n",
              "10epochs vs Original  0.368774  13.977532  0.077735   489.256303  8.677052e-07\n",
              "10epochs vs 2epochs  -0.004966   9.984358  0.142706  1223.179832  8.677052e-07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-911391c8-2479-4285-b762-cad1fe867ab3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SSIM</th>\n",
              "      <th>PSNR</th>\n",
              "      <th>LPIPS</th>\n",
              "      <th>FVD</th>\n",
              "      <th>Optical Flow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2epochs vs Original</th>\n",
              "      <td>0.011030</td>\n",
              "      <td>10.244824</td>\n",
              "      <td>0.121561</td>\n",
              "      <td>1068.556276</td>\n",
              "      <td>5.618801e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10epochs vs Original</th>\n",
              "      <td>0.368774</td>\n",
              "      <td>13.977532</td>\n",
              "      <td>0.077735</td>\n",
              "      <td>489.256303</td>\n",
              "      <td>8.677052e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10epochs vs 2epochs</th>\n",
              "      <td>-0.004966</td>\n",
              "      <td>9.984358</td>\n",
              "      <td>0.142706</td>\n",
              "      <td>1223.179832</td>\n",
              "      <td>8.677052e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-911391c8-2479-4285-b762-cad1fe867ab3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-911391c8-2479-4285-b762-cad1fe867ab3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-911391c8-2479-4285-b762-cad1fe867ab3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8f7bc990-65a3-419e-bc7b-55c29e2fa267\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f7bc990-65a3-419e-bc7b-55c29e2fa267')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8f7bc990-65a3-419e-bc7b-55c29e2fa267 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_94092f6e-15b6-49ba-85a2-567cac551e71\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_94092f6e-15b6-49ba-85a2-567cac551e71 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"SSIM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21131276107038466,\n        \"min\": -0.004965979492523,\n        \"max\": 0.36877438353880954,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.011030404282020215,\n          0.36877438353880954,\n          -0.004965979492523\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PSNR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.23406932584518,\n        \"min\": 9.984357831511897,\n        \"max\": 13.977532162372349,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          10.244823938212376,\n          13.977532162372349,\n          9.984357831511897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LPIPS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.033138372963326716,\n        \"min\": 0.07773542404174805,\n        \"max\": 0.14270572861035666,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.12156076729297638,\n          0.07773542404174805,\n          0.14270572861035666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FVD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 386.8980592282099,\n        \"min\": 489.2563032163272,\n        \"max\": 1223.1798322415962,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1068.556276398498,\n          489.2563032163272,\n          1223.1798322415962\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Optical Flow\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.743046431578514e-06,\n        \"min\": 8.677051823724469e-07,\n        \"max\": 5.618800969386939e-06,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8.677051823724469e-07,\n          5.618800969386939e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Web Test on motion_adapter_finetuned.pth Weights"
      ],
      "metadata": {
        "id": "-OQ3X6hl2jme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
        "from diffusers.utils import export_to_gif\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "device = \"cuda\"\n",
        "dtype = torch.float16\n",
        "\n",
        "step = 4  # Options: [1,2,4,8]\n",
        "repo = \"ByteDance/AnimateDiff-Lightning\"\n",
        "ckpt = f\"animatediff_lightning_{step}step_diffusers.safetensors\"\n",
        "base = \"emilianJR/epiCRealism\"  # Choose the base model.\n",
        "\n",
        "adapter = MotionAdapter().to(device, dtype)\n",
        "adapter.load_state_dict(load_file(hf_hub_download(repo, ckpt), device=device))\n",
        "pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
        "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
        "\n",
        "# Directly load the full fine-tuned MotionAdapter weights\n",
        "state_dict = torch.load(\"/content/drive/Shareddrives/DATA 298B Team 8/CODE/motion_adapter_finetuned.pth\", map_location=device)  # No need for `weights_only=True`\n",
        "adapter.load_state_dict(state_dict, strict=True)  # `strict=True` ensures weights match exactly\n",
        "\n",
        "pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
        "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
        "\n",
        "output = pipe(prompt=\"crack two eggs into a bowl\", guidance_scale=1.0, num_inference_steps=step)\n",
        "export_to_gif(output.frames[0], \"/content/drive/Shareddrives/DATA 298B Team 8/CODE/AnimateDiff_finetuned_animation.gif\")\n",
        "\n",
        "!pip install gradio diffusers huggingface_hub safetensors torch torchvision\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "import numpy as np\n",
        "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "from PIL import Image\n",
        "\n",
        "# Define Gradio processing function\n",
        "def generate_animation(prompt):\n",
        "    \"\"\"Generate an animation based on the user input text.\"\"\"\n",
        "    output = pipe(prompt=prompt, guidance_scale=1.0, num_inference_steps=step)\n",
        "\n",
        "    # Ensure output is in NumPy format\n",
        "    frames_np = np.array(output.frames, dtype=np.float32)  # Ensure float32 for precision\n",
        "\n",
        "    # Handle dimensions\n",
        "    if frames_np.ndim == 5:  # Possibly (batch, frames, H, W, C)\n",
        "        frames_np = frames_np.squeeze(0)\n",
        "\n",
        "    # Normalize values to range [0, 1] if they are outside the range\n",
        "    if frames_np.min() < 0 or frames_np.max() > 1:\n",
        "        frames_np = (frames_np - frames_np.min()) / (frames_np.max() - frames_np.min())\n",
        "\n",
        "    # Convert to RGB format (if necessary, some models output BGR or grayscale)\n",
        "    if frames_np.shape[-1] == 3:  # Assuming (frames, H, W, C)\n",
        "        frames_np = frames_np[..., ::-1]  # Convert BGR to RGB if necessary\n",
        "\n",
        "    # Convert NumPy array to PIL format\n",
        "    frames_pil = [Image.fromarray((frame * 255).astype(np.uint8), mode=\"RGB\") for frame in frames_np]\n",
        "\n",
        "    # Generate GIF\n",
        "    gif_path = \"/content/generated_animation.gif\"\n",
        "    frames_pil[0].save(gif_path, save_all=True, append_images=frames_pil[1:], duration=100, loop=0)\n",
        "\n",
        "    return gif_path\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_animation,\n",
        "    inputs=gr.Textbox(label=\"Enter a text prompt\"),\n",
        "    outputs=gr.Image(type=\"filepath\", label=\"Generated Animation\"),\n",
        "    title=\"Text to Video Web App\",\n",
        "    description=\"Enter a text description and generate an animation.\"\n",
        ")\n",
        "\n",
        "# Launch Web App\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b545a8ba4cc54da988e1fbfa16191752",
            "085bfe229bea4f6a979a12a949accb6e",
            "99034197bfb24c238910c464cf0127c4",
            "b7fbd82533d44bfe991d2c4e64bb69f3",
            "cfa010d9b6704937ba631b706c47edb6",
            "4334ee6a1ea847e6a80166893f098f5c",
            "0c2ca7f93dd549e6b707722f29732a5e",
            "7b9e3af7cf534ae5b49c8ac34fa241b3",
            "3551fe4de1cb4f41942d09f4d0bb2346",
            "b7f7bc9aa46748d2a0908df04d8f9474",
            "b75d3be7f8fe417fbaadb4f416c92266",
            "1c2a8cf3a2cf48fabe20e42ff5107c5d",
            "0eb1346e6fcc4cae9747e0c51fc46406",
            "1a97f865692a40a296b894d4a07bc5db",
            "442a6bba57b74c6aa81deb97cde33c5e",
            "1bd4505b92244c6f9ccfaf96f8a0a1fb",
            "713a5f179c024d969df341a47ce12be3",
            "fc76578e5f0140e6b774aa4bdfb9e33b",
            "c9d6589c42ad4dab84a279b6bd9502dc",
            "73293271801849c7a0d5bc7c725bc216",
            "73dd5f66f455462ea007c748eac3903b",
            "8b2ea9d0c7504834ad73835d9d7d8b73",
            "664ec976b2c9418a8079272a1a3e1aff",
            "d217d5f87e44496ebdf59d6fbabdd010",
            "b5306c158e5c44879a15c0225293efa1",
            "c1fb30bb4c67497ab53d41a4c5cfaa13",
            "85094a9858114417a7822748c84847df",
            "2a2effbdb9594f97af69f6613125eb3d",
            "9d438cb1340e48d9bb2c4f42c72c933f",
            "e99278469f9646bf96bd3aba89be30e3",
            "cc7a82d898ec4e48a8e7ca839149d69e",
            "4524ef17c7ce42f89e05046621d44c0b",
            "3d35fe921daf4b91b6b7b3fb098b9bdf"
          ]
        },
        "id": "fR46JVPrz-BP",
        "outputId": "6f082f18-4716-4c81-ef04-b9dd5aa5cd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b545a8ba4cc54da988e1fbfa16191752"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "<ipython-input-9-ee99824d57fc>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\"/content/drive/Shareddrives/DATA 298B Team 8/CODE/motion_adapter_finetuned.pth\", map_location=device)  # No need for `weights_only=True`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c2a8cf3a2cf48fabe20e42ff5107c5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "664ec976b2c9418a8079272a1a3e1aff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.20.0)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f7da19cf8897a35b94.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f7da19cf8897a35b94.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install piq\n",
        "\n",
        "import os, json, glob, random, gc\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import imageio\n",
        "import numpy as np\n",
        "import lpips\n",
        "import piq\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === Load annotation & sample ===\n",
        "annotation_path = \"/content/drive/Shareddrives/DATA 298B Team 8/298A/youcook/annotations/youcookii_annotations_trainval.json\"\n",
        "frame_dir = \"/content/drive/Shareddrives/DATA 298B Team 8/298A/processed_data/val\"\n",
        "\n",
        "with open(annotation_path, \"r\") as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "resize_only = transforms.Resize((256, 256))\n",
        "\n",
        "existing_ids = set([f.split(\"_sentence\")[0] for f in os.listdir(frame_dir) if \"_frames\" in f])\n",
        "valid_samples = []\n",
        "\n",
        "for vid, info in annotations[\"database\"].items():\n",
        "    if vid not in existing_ids: continue\n",
        "    for i, ann in enumerate(info[\"annotations\"]):\n",
        "        folder = f\"{vid}_sentence{i}_frames\"\n",
        "        path = os.path.join(frame_dir, folder)\n",
        "        frames = sorted(glob.glob(os.path.join(path, \"frame_*.jpg\")))\n",
        "        if os.path.isdir(path) and len(frames) >= 1:\n",
        "            valid_samples.append((frames[:1], ann[\"sentence\"]))\n",
        "\n",
        "frame_paths, prompt = random.choice(valid_samples)\n",
        "print(\"Prompt:\", prompt)\n",
        "\n",
        "# === Load 1 frame from GIF\n",
        "gif_path = \"/content/drive/Shareddrives/DATA 298B Team 8/CODE/AnimateDiff_finetuned_animation_4.6.gif\"\n",
        "gif = imageio.mimread(gif_path)\n",
        "gen_img = Image.fromarray(gif[0])  # only the first frame\n",
        "\n",
        "# === LPIPS + SSIM + PSNR\n",
        "loss_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "real_tensor = transform(Image.open(frame_paths[0]).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "gen_tensor = transform(gen_img).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    lpips_score = loss_fn(real_tensor, gen_tensor).item()\n",
        "    ssim_score = piq.ssim(gen_tensor, real_tensor, data_range=1.0).item()\n",
        "    psnr_score = piq.psnr(gen_tensor, real_tensor, data_range=1.0).item()\n",
        "\n",
        "del real_tensor, gen_tensor\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# === FVD (over single frame)\n",
        "def fvd_single(real_path, gen_pil):\n",
        "    r = np.array(resize_only(Image.open(real_path))).astype(np.float32).flatten()\n",
        "    g = np.array(resize_only(gen_pil)).astype(np.float32).flatten()\n",
        "    mu1, mu2 = r.mean(), g.mean()\n",
        "    sigma1, sigma2 = r.std(), g.std()\n",
        "    return (mu1 - mu2) ** 2 + (sigma1 + sigma2 - 2 * np.sqrt(sigma1 * sigma2))\n",
        "\n",
        "fvd_score = fvd_single(frame_paths[0], gen_img)\n",
        "\n",
        "# === CLIP (1 frame only)\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\").to(device)\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "clip_inputs = clip_processor(text=prompt, images=gen_img, return_tensors=\"pt\").to(device)\n",
        "clip_outputs = clip_model(**clip_inputs)\n",
        "clip_score = clip_outputs.logits_per_image.mean().item()\n",
        "\n",
        "# === Final output\n",
        "print({\n",
        "    \"Prompt\": prompt,\n",
        "    \"LPIPS\": lpips_score,\n",
        "    \"SSIM\": ssim_score,\n",
        "    \"PSNR\": psnr_score,\n",
        "    \"FVD\": fvd_score,\n",
        "    \"CLIP Score\": clip_score\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585,
          "referenced_widgets": [
            "126ecf69833d49ccb4049d09b6a11122",
            "63abbcd5839a4323a8d341c4e5a8743a",
            "906799c147234032a0b73f2dec4fbc2f",
            "08e4f70f58e34dc3bd5d1907c1f801d1",
            "846d6c55110946d2a1abc8661c67ec70",
            "955d267c7253447dae9192edecfa03de",
            "3497af21d3364f1e81c88482adc5caf9",
            "194c677888244058a9d5b228f1f90ace",
            "eb113b0afed947acac00f6fb4c23bbb7",
            "98fcd8350bbd46d480a07e3501cae0e6",
            "5e645a49799547a2a3e901d396c8cc23",
            "8a729a80a09648c3b372dd8208570a1a",
            "c2b6c7967d924a72b185efa9ea64ae86",
            "722f765794fd46de802ba8e08287c2d6",
            "b71066830b064d71afe72e8447a8265b",
            "631e7a8de5734276bc9ca6e245888c74",
            "d812a401ce9b407297cd71eddd1b5a1f",
            "3a53c0501d36457cb6f4ba55cf336e28",
            "d92a85d601904563a264a9b2e00752ca",
            "1058d4b8964f4d0995de0542268623d2",
            "a27f3482c8d848c88ca16354b7a69ca2",
            "4c095f90364341aa8d48edd660ae3f30",
            "0f02aedf4a844992a79579d411dcbe89",
            "a79f3224abf74a6081d39147aca2fff0",
            "67e90f72728145b4ad329eacb1d30022",
            "3993bbc9fd9a4f61ab44bfe90d2da428",
            "de57b967a0a7486f9261ed00ff608407",
            "4ef81828ca8d4d51a57e484b549633d4",
            "45b61e7859124c7eb1672f83cd973df0",
            "7f0351e971e54a459024abf0b9378e32",
            "44ba06ba1ee34c1c826a0437154c5868",
            "85375c059bb54b09b07f606b8a09bbec",
            "026fecf0183443b5874799c087c4ff56",
            "1b862ca05ce042fdae0a3cde7a4e3099",
            "4dc7a6bf78a843ff8e5b7d3868cbbd56",
            "e33a317dc3384a6986a1e4666906d23e",
            "fe4f9ec347074e5d8370303b538b8096",
            "be1f1fa4c1f9438296b3d10978cdafc9",
            "d599b5e255af4869a3cc38afd6314455",
            "0ba6ad493eba4c75814a1e7cd421a0ea",
            "45862c5808604485bc11628cac260f0f",
            "5c1f71d1bba946a0983746155740b3f7",
            "5a94dc9d41834055ab53836be2952b8f",
            "4a45571edc91473aabdddcec28cce858",
            "c5a5b00cdfa949449e97c4e2b5adcada",
            "8dabcf78d6f747d6af4f96914e8b7957",
            "3a6ae35ed3a64a2f8b06b7b9773a4c66",
            "47460cfaafa44b0388487d7cfd292687",
            "a9a40318addc4441bce62613b2bd3a8a",
            "3902f1c4a8c1401c8f8dfe3b2d975cc1",
            "bc0daaea7a634badbe5e7016204ee445",
            "d70dcdf9053141aab02427c5ba201a7f",
            "5f07b309e7e543658ce0bfb63f83a8ce",
            "3f6497a72bbb4817b37594234a9df320",
            "ba0d70f1cf634932a82fa8f0aa38d22b",
            "9eb8334ca1bd4117b3618b37946e1f88",
            "337bc1e0600f46db991459583fcb862a",
            "3e8b1fcbe5174f6b876bd3e4e382ce21",
            "51b81c5b89a74deca87d2c6a2b13b47a",
            "217ed4951af54f1da23c45aa3fbdab94",
            "12ba889583494ba0adf1453d274fbd03",
            "fe1be7369bba40faaf8c043064b899c6",
            "c067de72c0ed4fa8ac49396b1bc2d2f3",
            "30b140bddaf241c1888605ef673cc6af",
            "2d72ef8e4dd747f9a123b8cc0a1abd3b",
            "90b1e4148cf144b98204f3c073bde39c",
            "83e1cde4c12446d49073c5e5d55e2782",
            "954e4fee13f94ca4a33816dc0f57a974",
            "e7aed1b695334832ad7ce0df34ed2328",
            "4c47a7309ab448fab7d6e3263eaa433f",
            "e43b089bb6e84c20aae758b216edf645",
            "7d88fef5baa24a92b647efe1e39f75c2",
            "f7209576a2c247c4b20164ab84d99b9c",
            "be082827b9ca40a1b308805a6337d00e",
            "895b6597d36d44f5a694337f128ee733",
            "c6ded3f7deee4fa482b0b17d9a0f6c2c",
            "162ea9f712544ec7b6365187490492a2",
            "8299dff8ded0443e8cdec96131fdbed1",
            "43820580675e4bfa8132d094ffac403f",
            "8dfca53091ec49f3a15a8282ab823d6f",
            "f036d3ac57f94d48a735bb6a32273120",
            "5276c397fa2f4e44a7bb9145c92966f0",
            "90cc6a860d184d0db7bcb1d2792a87f4",
            "df62d3d57c504b5bbc15e9074228367f",
            "5dd228fa8f8e42669df6578f104eac04",
            "80b3eb2113174058be73ebc7853b3840",
            "63753e19af584661b6c670b8fa26e67d",
            "2a23e213116547169b96d29844e57f3f",
            "16a9bd7e7a59427f8452b785c3e63fa6",
            "918fa7afb2d24ee59d9f7aadb83bad1c",
            "aa7302fcdf8640c69ae5d4d7d4a470c4",
            "ec879c86978b4c958ddb859a8b75d5dd",
            "bf0769701afe4643b8607721f8de37bf",
            "75fc62cf2031443ea7df7a502f22c76c",
            "a6108ce9f09e4e68b13898bec25382f8",
            "d8b32e331c254c08b194d6e5657e43ad",
            "a8c5fb6d736b4b0c9d4ac988c08b543b",
            "c82f09276d29409ca4e25f9fd09e6cae",
            "b724074cf7804148a35910a87b6f161a"
          ]
        },
        "outputId": "5f9d67db-23bf-4099-b108-a124755db5f6",
        "id": "_PJOmktdKaE1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: use a tablespoon to make balls out of the mashed potatoes\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.10k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "126ecf69833d49ccb4049d09b6a11122"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/599M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a729a80a09648c3b372dd8208570a1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f02aedf4a844992a79579d411dcbe89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b862ca05ce042fdae0a3cde7a4e3099"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5a5b00cdfa949449e97c4e2b5adcada"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eb8334ca1bd4117b3618b37946e1f88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83e1cde4c12446d49073c5e5d55e2782"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8299dff8ded0443e8cdec96131fdbed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16a9bd7e7a59427f8452b785c3e63fa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Prompt': 'use a tablespoon to make balls out of the mashed potatoes', 'LPIPS': 0.7376506328582764, 'SSIM': 0.0040740687400102615, 'PSNR': 5.727221488952637, 'FVD': np.float32(13616.206), 'CLIP Score': 26.30241584777832}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import imageio\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Grayscale\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "annotation_path = \"/content/drive/Shareddrives/DATA 298B Team 8/298A/youcook/annotations/youcookii_annotations_trainval.json\"\n",
        "frame_dir = \"/content/drive/Shareddrives/DATA 298B Team 8/298A/processed_data/val\"\n",
        "gif_path = \"/content/drive/Shareddrives/DATA 298B Team 8/CODE/AnimateDiff_finetuned_animation_4.6.gif\"\n",
        "resize_only = transforms.Resize((256, 256))\n",
        "# ============================\n",
        "\n",
        "# === Load annotations\n",
        "with open(annotation_path, \"r\") as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "existing_ids = set([f.split(\"_sentence\")[0] for f in os.listdir(frame_dir) if \"_frames\" in f])\n",
        "\n",
        "# === Find valid sample\n",
        "valid_samples = []\n",
        "for vid, info in annotations[\"database\"].items():\n",
        "    if vid not in existing_ids:\n",
        "        continue\n",
        "    for i, ann in enumerate(info[\"annotations\"]):\n",
        "        folder = f\"{vid}_sentence{i}_frames\"\n",
        "        path = os.path.join(frame_dir, folder)\n",
        "        frames = sorted(glob.glob(os.path.join(path, \"frame_*.jpg\")))\n",
        "        if os.path.isdir(path) and len(frames) >= 2:\n",
        "            valid_samples.append((frames[:2], ann[\"sentence\"]))\n",
        "\n",
        "# === Pick one sample\n",
        "frame_paths, prompt = valid_samples[0]\n",
        "gif = imageio.mimread(gif_path)\n",
        "\n",
        "resize_64_gray = Compose([\n",
        "    Resize((64, 64)),\n",
        "    Grayscale(),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "def fvd_lightweight(real_paths, gen_frames, num_frames=2):\n",
        "    real_feats, gen_feats = [], []\n",
        "    for i in range(num_frames):\n",
        "        r = resize_64_gray(Image.open(real_paths[i])).view(-1).numpy()\n",
        "        g = resize_64_gray(Image.fromarray(gen_frames[i])).view(-1).numpy()\n",
        "        real_feats.append(r)\n",
        "        gen_feats.append(g)\n",
        "    real_feats = np.stack(real_feats)\n",
        "    gen_feats = np.stack(gen_feats)\n",
        "\n",
        "    mu_r, mu_g = real_feats.mean(0), gen_feats.mean(0)\n",
        "    sigma_r = np.cov(real_feats, rowvar=False)\n",
        "    sigma_g = np.cov(gen_feats, rowvar=False)\n",
        "\n",
        "    diff = np.sum((mu_r - mu_g) ** 2)\n",
        "    trace_cov = np.trace(sigma_r) + np.trace(sigma_g) - 2 * np.sqrt(np.trace(sigma_r) * np.trace(sigma_g))\n",
        "    return float(diff + trace_cov)\n",
        "\n",
        "# === Compute FVD\n",
        "n_fvd = min(2, len(frame_paths), len(gif))\n",
        "fvd_score = fvd_lightweight(frame_paths, gif, num_frames=n_fvd)\n",
        "\n",
        "\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(f\"FVD (2-frame): {fvd_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I97NqV6eHFMt",
        "outputId": "be774064-8e53-4687-a295-86631a2957f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: heat some oil in a pan with garlic and cumin seeds\n",
            "FVD (2-frame): 436.5696\n"
          ]
        }
      ]
    }
  ]
}